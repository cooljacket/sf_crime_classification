# bugs
1. [03/13 23:50]我发现我之前做的输出是错的，难怪这么低的得分。。因为我以为是输入0,0,0,0,0,1,0,0,0这样的格式，而其实真正的规定是每个sample在每个犯罪类别上的概率，即0.1, 0.005, 0.8, ...这样子。


# 代码结构
- trans_data.cpp	将原始csv格式转化为需要的文本数据
- do_xxx.py		后面跟着的是所用的算法的简写，每个基本都是一样的，只是所用的模型不一样而已
- utils.py		是自己写的读入数据、写出结果、展示数据、压缩文件的工具库


# 思路发展的说明
1. 数据预处理
首先是将原始数据（record格式，即有很多是字符串的描述）转化为data matrix格式（即全部为数据的格式），具体的转换放在在trans_data.cpp中有描述清楚。


2. 特征的选择
这部分是最重要部分之一（另外一部分是选择合适的模型和参数），训练数据和测试数据共有的特征有:
	* 1）Dates；
	* 2）DayOfWeek；
	* 3）PdDistrict；
	* 4）X（Longitude）；
	* 5）Y（Latitude）。
所以只能在这五个维度的基础上来做。
具体怎么做呢？应该需要用到“特征工程”的一些知识（待讨论，参考：https://www.zhihu.com/question/28641663）。

3. 发现nominal的特征如果向量化的话，效果可能会很好！
比如DayOfWeek这个量就是属于nominal的，因为它只能比较，不同的星期几之间是并列平等的关系。考虑把原来的1,2,3,4,5,6,7变成[1000000],[0100000],...这样子，效果待实验来验证！(03/14)


# 已经做过的事
- 1）标准化特征值（但是没什么明显的改进）；
- 2）尝试使用SGD（但是效果很差，原因未知）；
- 3）尝试使用SVM，但是由于数据太多，训练太慢了，跑了一天都每跑出来；

	

# 现在正在做的事
[03/12]我现在正在尝试用合理的方法将数据归一化，再跑一遍试试看结果(√)
[03/14]准备试一下将Nominal的特征向量化试试看



# 需要大家做的事
- 1）学会用scikit-learn库或者别的库，来做相关性分析；
- 2）看一下如何选取特征比较好，模型方面可以暂时我来写就好了，等到后面有教再大家一起做。
- 3）[later]看能不能将犯罪的地点和种类在实际的地图上可视化出来，python的地图库参考：http://www.oschina.net/translate/python-maps-chloropleth，而地图文件参考：http://www.openstreetmap.org/relation/111968#map=11/37.7685/-122.4457。
- 4）


# 数据标准化
用了两种方法：

* 1）min-max：即x = (x-min) / (max-min)，将数据范围归一化到(-1,1)上；
* 2）使用均值和标准差：x = (x-avg) / std
发现两种的效果都差不多，几乎是一样的，后续不再区分，默认使用min-max。
但是效果好像不咋地。。。（目前用的是未向量化的特征，发现即使没有手动标准化，跑出来的结果也是一样的，对于logistic regression来说。。。）



# 以后报告可以写的点
1. 相关性的分析：比如犯罪类型与星期几有没有关系，与每天中的哪个钟点有没有关系等等，有什么用呢？做为特征选择的依据，比如如果发现天数跟犯罪类型基本没关系，那也就没必要将它列入分类的特征之一；
2. 可视化：把犯罪在地理位置上的分布可视化出来？
3. Baseline：前两个都是有点装逼的点，这个就比较重要了，比如我们可以根据每个犯罪分类的出现的频率，全部填上这个统计的值，来作为基准，比较可以得出模型的好坏（其实跟leaderboard上面的人的成绩比较就可以了，不过这个会比较客观一点）；
4. Nominal特征的向量化的效果；
5. 

